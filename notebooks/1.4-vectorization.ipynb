{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e13ae2a-0b5a-488a-9ea4-f6807021e9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aabel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\aabel\\Envs\\drug-labels\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import re\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from cleaning import remove_punctuation, remove_numbers, tokenize, remove_stopwords, prepare\n",
    "\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ad46a-78c2-4612-a7fd-32da9ed987fd",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571b70b3-1580-4fdb-bc63-2f830153cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/interim/drugs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242f4797-4cb2-4147-b5bf-f18a3d4608da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>DOSAGE Adults- Take 4 or 6 Pellets by mouth, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>DIRECTIONS Adults: Dissolve 3 to 5 under the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OPHTHALMIC</td>\n",
       "      <td>DOSAGE AND ADMINISTRATION The recommended dosa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>2 DOSAGE AND ADMINISTRATION Use the lowest eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOPICAL</td>\n",
       "      <td>Directions wet face, apply to hand, massage fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                               text\n",
       "0        ORAL  DOSAGE Adults- Take 4 or 6 Pellets by mouth, t...\n",
       "1        ORAL  DIRECTIONS Adults: Dissolve 3 to 5 under the t...\n",
       "2  OPHTHALMIC  DOSAGE AND ADMINISTRATION The recommended dosa...\n",
       "3        ORAL  2 DOSAGE AND ADMINISTRATION Use the lowest eff...\n",
       "4     TOPICAL  Directions wet face, apply to hand, massage fa..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8fb304-f138-4559-8571-b3714e13fafb",
   "metadata": {},
   "source": [
    "Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a84c5e-d56b-4209-9891-a75ee7166afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>DOSAGE Adults- Take 4 or 6 Pellets by mouth, t...</td>\n",
       "      <td>[adults, take, pellets, mouth, three, times, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>DIRECTIONS Adults: Dissolve 3 to 5 under the t...</td>\n",
       "      <td>[adults, dissolve, tongue, three, times, day, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OPHTHALMIC</td>\n",
       "      <td>DOSAGE AND ADMINISTRATION The recommended dosa...</td>\n",
       "      <td>[recommended, regimen, treatment, bacterial, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>2 DOSAGE AND ADMINISTRATION Use the lowest eff...</td>\n",
       "      <td>[use, lowest, effective, shortest, duration, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOPICAL</td>\n",
       "      <td>Directions wet face, apply to hand, massage fa...</td>\n",
       "      <td>[wet, face, apply, hand, massage, face, gently...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                               text  \\\n",
       "0        ORAL  DOSAGE Adults- Take 4 or 6 Pellets by mouth, t...   \n",
       "1        ORAL  DIRECTIONS Adults: Dissolve 3 to 5 under the t...   \n",
       "2  OPHTHALMIC  DOSAGE AND ADMINISTRATION The recommended dosa...   \n",
       "3        ORAL  2 DOSAGE AND ADMINISTRATION Use the lowest eff...   \n",
       "4     TOPICAL  Directions wet face, apply to hand, massage fa...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [adults, take, pellets, mouth, three, times, d...  \n",
       "1  [adults, dissolve, tongue, three, times, day, ...  \n",
       "2  [recommended, regimen, treatment, bacterial, c...  \n",
       "3  [use, lowest, effective, shortest, duration, c...  \n",
       "4  [wet, face, apply, hand, massage, face, gently...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = [str.lower, remove_punctuation, remove_numbers, tokenize, remove_stopwords]\n",
    "df['tokens'] = df['text'].apply(prepare, pipeline=pipeline)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036c482-179d-4f87-beff-a0bb04436c63",
   "metadata": {},
   "source": [
    "The simplest tokenization just splits on whitespace. Let's try this and explore the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30a829-06c9-4257-ac8a-ffceab4ed295",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [str.lower, str.split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f0dfb-6416-4517-9f8d-e1d1c9e3a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['text'].apply(prepare, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ffebc-38da-4946-86c0-cfe48f37bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a84bc-c342-48a1-85f2-e9ebf3cc6248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all tokens\n",
    "all_tokens = []\n",
    "df['tokens'].apply(lambda x: all_tokens.extend(x))\n",
    "print(len(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa54e9c-e3ec-47d9-88c9-dbec3f60d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc646244-b3c7-47a6-bc2f-07dbd5dc64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = token_counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e2c2d-6ea1-40b2-91ef-b588245da231",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting on whitespace yields {0} tokens and {1} types.\".format(token_counts.total(), len(types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05318cd0-e244-4711-8ca7-12e94073bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6efcb70-f723-4283-b630-6b2240d8582b",
   "metadata": {},
   "source": [
    "The top 30 typtes contain many stopwords. A few of them contain punctuation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e6e1f9-f421-4395-85be-f3008dfb7096",
   "metadata": {},
   "source": [
    "Let's look for other types containing punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69604c62-a3a6-482d-9a53-a7cdab818895",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_set = set(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f500914-08ad-44b8-8973-3a78991956e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_punct(text):\n",
    "    for char in text:\n",
    "        if char in punct_set:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c119d12-4276-4ff4-9817-81da2642fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "types_with_punct = {t: count for t, count in token_counts.items() if contains_punct(t)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575cf97c-2afb-4114-ae71-b410c2674c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "types_with_punct = sorted(types_with_punct.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07bf5b6-e636-4e73-b8ce-fc5ff8f66799",
   "metadata": {},
   "outputs": [],
   "source": [
    "types_with_punct[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a13515-2ce4-4ef2-89d7-947c8b0c10e1",
   "metadata": {},
   "source": [
    "It seems fairly common for words to be combined with '/'. Let's take a look at these specifically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e095b-f091-4a27-8593-5966c07a1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(t, count) for t, count in dict(types_with_punct).items() if '/' in t][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e1784a-6fdd-4344-9b07-83c66d5dc43e",
   "metadata": {},
   "source": [
    "Most of these represent units of measurement (e.g. 'mg/day'). However, some of them represent combinations of distinct concepts (e.g. 'caregiver/family', 'pharyngitis/tonsillitis'). Splitting on whitespace would treat these as a single token, which would add unnecessary noise to the corpus. Let's try splitting on whitespace AND on '/'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a46bed-9788-4388-9f98-70dd57042891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    pattern = re.compile(r'[\\s/]')\n",
    "    tokens = re.split(pattern, text)\n",
    "    tokens = [t for t in tokens if t != '']\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156bac10-4d72-40cb-a93e-ce5dc12a3db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize('mg/day foo bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f71ad7-0b16-4c36-b6ab-25f3a4d4dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [str.lower, tokenize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d13b1b0-44ac-49e8-b73f-a2531ec216ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_slash'] = df['text'].apply(prepare, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c2745-d93d-496d-ba30-895fe7db21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5e555-3731-4224-9333-7cb0cdda1ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all tokens\n",
    "all_tokens = []\n",
    "df['tokens_slash'].apply(lambda x: all_tokens.extend(x))\n",
    "print(len(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341513d5-8a87-420f-af53-f7ca0618bec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99795367-7b6a-4262-9a28-0fbcdab7b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = token_counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df6377-0a3f-4306-885d-e8e4e2375476",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting on whitespace and '/' yields {0} tokens and {1} types.\".format(token_counts.total(), len(types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823232ac-7abd-4075-bce0-f7b8a1d0ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bb168b-9503-48d3-98fc-8d8b171451a7",
   "metadata": {},
   "source": [
    "Some of the most common types also included '-'. Let's take a look at them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19271f2-f27b-4e6b-8f50-21c9982db33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "{t: count for t, count in token_counts.items() if '-' in t}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f8450-2339-4406-a539-ae9959c4a7e6",
   "metadata": {},
   "source": [
    "In contrast to words combined with '/', these combined with '-' tend to represent a single concept. Splitting them into separate tokens would lose important information (e.g. 'non-psychotic'). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3a62c-6dfc-4e30-8e5c-58c934a1e83f",
   "metadata": {},
   "source": [
    "Based on the above analysis, we will split on whitespace and '/', and remove punctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d669e7-a63f-4e82-90b1-d66fb734313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_set = set(punctuation)\n",
    "punct_set.remove('/') # don't remove '/' because we need it for tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73606d9-0744-4c73-8b31-c955ec4ae9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return \"\".join([char for char in text if char not in punct_set])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453924cc-5ebc-4523-b3d1-f9247285dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [str.lower, remove_punctuation, tokenize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238eb5cd-a3ff-40b3-9b17-a1dd71a41734",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare('This is an example/test sentence!', pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f2ef98-85d7-4502-b790-96e5a066f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_final'] = df['text'].apply(prepare, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b375b3-f87b-423b-8731-6aca1f424e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec82db-c66f-4633-9b37-bf06a91f98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all tokens\n",
    "all_tokens = []\n",
    "df['tokens_final'].apply(lambda x: all_tokens.extend(x))\n",
    "print(len(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec1f331-3b7a-4012-a152-37ca7965147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39381f4-cdae-4e7d-a57b-d397f38f3a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = token_counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b49959-9024-4c87-b543-cbd933ef39c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting on whitespace and '/' and removing punctuation yields {0} tokens and {1} types.\".format(token_counts.total(), len(types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ebd3d-d70d-46fe-b5cc-7c821c01ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19520615",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Vectorization - BERT (Google NLP Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4be95d7-ae19-4821-95ef-891553fb9d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>DOSAGE Adults- Take 4 or 6 Pellets by mouth, t...</td>\n",
       "      <td>[adults, take, pellets, mouth, three, times, d...</td>\n",
       "      <td>adults take pellets mouth three times daily su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>DIRECTIONS Adults: Dissolve 3 to 5 under the t...</td>\n",
       "      <td>[adults, dissolve, tongue, three, times, day, ...</td>\n",
       "      <td>adults dissolve tongue three times day directe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OPHTHALMIC</td>\n",
       "      <td>DOSAGE AND ADMINISTRATION The recommended dosa...</td>\n",
       "      <td>[recommended, regimen, treatment, bacterial, c...</td>\n",
       "      <td>recommended regimen treatment bacterial conjun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>2 DOSAGE AND ADMINISTRATION Use the lowest eff...</td>\n",
       "      <td>[use, lowest, effective, shortest, duration, c...</td>\n",
       "      <td>use lowest effective shortest duration consist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOPICAL</td>\n",
       "      <td>Directions wet face, apply to hand, massage fa...</td>\n",
       "      <td>[wet, face, apply, hand, massage, face, gently...</td>\n",
       "      <td>wet face apply hand massage face gently rinse ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                               text  \\\n",
       "0        ORAL  DOSAGE Adults- Take 4 or 6 Pellets by mouth, t...   \n",
       "1        ORAL  DIRECTIONS Adults: Dissolve 3 to 5 under the t...   \n",
       "2  OPHTHALMIC  DOSAGE AND ADMINISTRATION The recommended dosa...   \n",
       "3        ORAL  2 DOSAGE AND ADMINISTRATION Use the lowest eff...   \n",
       "4     TOPICAL  Directions wet face, apply to hand, massage fa...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [adults, take, pellets, mouth, three, times, d...   \n",
       "1  [adults, dissolve, tongue, three, times, day, ...   \n",
       "2  [recommended, regimen, treatment, bacterial, c...   \n",
       "3  [use, lowest, effective, shortest, duration, c...   \n",
       "4  [wet, face, apply, hand, massage, face, gently...   \n",
       "\n",
       "                                          final_text  \n",
       "0  adults take pellets mouth three times daily su...  \n",
       "1  adults dissolve tongue three times day directe...  \n",
       "2  recommended regimen treatment bacterial conjun...  \n",
       "3  use lowest effective shortest duration consist...  \n",
       "4  wet face apply hand massage face gently rinse ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create final sentence, based on final tokens, to vectorize via semantic model\n",
    "\n",
    "def join_text(tokens):\n",
    "    new_text = ' '.join(tokens)\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "df['final_text'] = df.apply(lambda row: join_text(row['tokens']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1147203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utilizing Google's NLP vectorization model - applied via SentenceTransformer. \n",
    "model = SentenceTransformer('bert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d91a3139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>final_text</th>\n",
       "      <th>bert_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>DOSAGE Adults- Take 4 or 6 Pellets by mouth, t...</td>\n",
       "      <td>[adults, take, pellets, mouth, three, times, d...</td>\n",
       "      <td>adults take pellets mouth three times daily su...</td>\n",
       "      <td>[-0.25533915, 0.98093414, 0.47458115, -0.46995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>DIRECTIONS Adults: Dissolve 3 to 5 under the t...</td>\n",
       "      <td>[adults, dissolve, tongue, three, times, day, ...</td>\n",
       "      <td>adults dissolve tongue three times day directe...</td>\n",
       "      <td>[-0.32527256, 0.80431247, 0.6453381, 0.1251983...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OPHTHALMIC</td>\n",
       "      <td>DOSAGE AND ADMINISTRATION The recommended dosa...</td>\n",
       "      <td>[recommended, regimen, treatment, bacterial, c...</td>\n",
       "      <td>recommended regimen treatment bacterial conjun...</td>\n",
       "      <td>[0.18958697, 0.0632698, 0.662766, 0.13524653, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORAL</td>\n",
       "      <td>2 DOSAGE AND ADMINISTRATION Use the lowest eff...</td>\n",
       "      <td>[use, lowest, effective, shortest, duration, c...</td>\n",
       "      <td>use lowest effective shortest duration consist...</td>\n",
       "      <td>[-0.6896909, 0.2681557, 0.34398147, -0.2088281...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOPICAL</td>\n",
       "      <td>Directions wet face, apply to hand, massage fa...</td>\n",
       "      <td>[wet, face, apply, hand, massage, face, gently...</td>\n",
       "      <td>wet face apply hand massage face gently rinse ...</td>\n",
       "      <td>[0.16621587, 0.8684128, 1.0205474, 0.43868583,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                               text  \\\n",
       "0        ORAL  DOSAGE Adults- Take 4 or 6 Pellets by mouth, t...   \n",
       "1        ORAL  DIRECTIONS Adults: Dissolve 3 to 5 under the t...   \n",
       "2  OPHTHALMIC  DOSAGE AND ADMINISTRATION The recommended dosa...   \n",
       "3        ORAL  2 DOSAGE AND ADMINISTRATION Use the lowest eff...   \n",
       "4     TOPICAL  Directions wet face, apply to hand, massage fa...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [adults, take, pellets, mouth, three, times, d...   \n",
       "1  [adults, dissolve, tongue, three, times, day, ...   \n",
       "2  [recommended, regimen, treatment, bacterial, c...   \n",
       "3  [use, lowest, effective, shortest, duration, c...   \n",
       "4  [wet, face, apply, hand, massage, face, gently...   \n",
       "\n",
       "                                          final_text  \\\n",
       "0  adults take pellets mouth three times daily su...   \n",
       "1  adults dissolve tongue three times day directe...   \n",
       "2  recommended regimen treatment bacterial conjun...   \n",
       "3  use lowest effective shortest duration consist...   \n",
       "4  wet face apply hand massage face gently rinse ...   \n",
       "\n",
       "                                         bert_vector  \n",
       "0  [-0.25533915, 0.98093414, 0.47458115, -0.46995...  \n",
       "1  [-0.32527256, 0.80431247, 0.6453381, 0.1251983...  \n",
       "2  [0.18958697, 0.0632698, 0.662766, 0.13524653, ...  \n",
       "3  [-0.6896909, 0.2681557, 0.34398147, -0.2088281...  \n",
       "4  [0.16621587, 0.8684128, 1.0205474, 0.43868583,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create vector using BERT Model\n",
    "\n",
    "bert_vector = model.encode(df['final_text'].astype(str))\n",
    "df['bert_vector'] = list(bert_vector)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67421c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../data/processed/drugs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb319c-29b3-4df1-86b3-84e02c8af80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
