{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2b3a96e-b558-403d-934a-b16293ef0cde",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc465c3-7e58-4241-a135-e666f13c3428",
   "metadata": {},
   "source": [
    "This code compares the trained classifier and topic model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1ba45f-a628-4e58-9b03-c0ce4be1d85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aabel\\Envs\\drug-labels\\lib\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a582e2-8bff-487e-a184-3dedbff755f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained models \n",
    "with open('../models/classifier.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "with open('../models/classifier_features.pkl', 'rb') as f:\n",
    "    clf_features = pickle.load(f)\n",
    "with open('../models/lda_model.pkl', 'rb') as f:\n",
    "    tm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba4c91f-2b32-4d36-864a-7faa2697c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset \n",
    "df = pd.read_pickle('../data/processed/drugs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a423f84-90b9-4e8d-b7e6-5e65a9157b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORAL', 'OTHER', 'TOPICAL', 'INTRAVENOUS', 'INTRAMUSCULAR', 'DENTAL']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new dataframe with just the top 5 classes\n",
    "df.loc[~df['target'].isin(['ORAL', 'TOPICAL', 'INTRAVENOUS', 'DENTAL', 'INTRAMUSCULAR']), 'target'] = 'OTHER'\n",
    "list(df['target'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56571222-c45b-426f-be73-c79852992dc1",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e6bb0a-473a-443c-b4da-fb7a727302d4",
   "metadata": {},
   "source": [
    "As shown in the Classifier section above, the Naive Bayes model is 70% accurate on the test data. Below is its precision and recall on each class. \n",
    "\n",
    "|Class        |Precision|Recall|F1-Score|\n",
    "|-------------|---------|------|--------|\n",
    "|ORAL         |98%      |63%   |77%     |\n",
    "|TOPICAL      |99%      |80%   |88%     |\n",
    "|OTHER        |49%      |64%   |56%     |\n",
    "|INTRAVENOUS  |17%      |96%   |29%     |\n",
    "|DENTAL       |64%      |92%   |75%     |\n",
    "|INTRAMUSCULAR|16%      |97%   |27%     |\n",
    "\n",
    "The model is best at classifying TOPICAL drugs, with the highest F1-score of 88%. It is also pretty good at classifying ORAL drugs, with an F1-score of 77%. Both classes have very high precision, which means if the model predicts ORAL or TOPICAL, we can be very confident in those predictions. \n",
    "\n",
    "In contrast, the model struggles the most with INTRAMUSCULAR and INTRAVENOUS drugs, which have high recall but very low precision. That means the model predicts those classes more often than it should, or in other words is hypersensitive to those classes. This is reflected in the list of most informative features, which is dominated by the INTRAVENOUS and INTRAMUSCULAR classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aad1439-a207-4555-b4ad-10cd286fd472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  stable = True           INTRAV : TOPICA =   5773.3 : 1.0\n",
      "                 reapply = True           TOPICA : ORAL   =   5678.6 : 1.0\n",
      "                      iv = True           INTRAM : TOPICA =   5671.7 : 1.0\n",
      "                swimming = True           TOPICA : ORAL   =   5494.4 : 1.0\n",
      "                injected = True           INTRAM : TOPICA =   5389.8 : 1.0\n",
      "                 diluted = True           INTRAV : TOPICA =   5323.3 : 1.0\n",
      "                   aging = True           TOPICA : ORAL   =   4970.6 : 1.0\n",
      "                spectrum = True           TOPICA : ORAL   =   4598.6 : 1.0\n",
      "          reconstitution = True           INTRAV : TOPICA =   4483.1 : 1.0\n",
      "                lactated = True           INTRAV : TOPICA =   4308.1 : 1.0\n",
      "          individualized = True           INTRAM : TOPICA =   4168.2 : 1.0\n",
      "                     rub = True           TOPICA : ORAL   =   4052.5 : 1.0\n",
      "                 divided = True           INTRAM : TOPICA =   4047.4 : 1.0\n",
      "                 tablets = True             ORAL : TOPICA =   3500.7 : 1.0\n",
      "                     sun = True           TOPICA : ORAL   =   3455.4 : 1.0\n",
      "                  caries = True           DENTAL : ORAL   =   3417.4 : 1.0\n",
      "            refrigerated = True           INTRAV : TOPICA =   3283.7 : 1.0\n",
      "                   acute = True           INTRAM : TOPICA =   3266.1 : 1.0\n",
      "           precipitation = True           INTRAM : TOPICA =   3228.5 : 1.0\n",
      "           postoperative = True           INTRAM : TOPICA =   3067.4 : 1.0\n",
      "                    bags = True           INTRAV : TOPICA =   2959.6 : 1.0\n",
      "                   heart = True           INTRAV : TOPICA =   2849.4 : 1.0\n",
      "                 hepatic = True           INTRAV : TOPICA =   2836.4 : 1.0\n",
      "                  fluids = True           INTRAV : TOPICA =   2810.5 : 1.0\n",
      "           discoloration = True           INTRAV : TOPICA =   2772.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "clf.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c0309d-2a50-4bad-adaf-1d5070b45860",
   "metadata": {},
   "source": [
    "## Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4492c50-8ea0-4361-a54a-a485f45895bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85328, 13217)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bag-of-words\n",
    "count_vectorizer = CountVectorizer(min_df=5, max_df=0.7)\n",
    "count_vectors = count_vectorizer.fit_transform(df['tokens_str'])\n",
    "count_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cafc940b-d569-4a41-859f-ffc618fb2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function comes from the blueprint for text analytics \n",
    "\n",
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88855f4-9da8-4a15-809c-9845c1047a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the LDA model to the original tallys\n",
    "document_topic_matrix = tm.fit_transform(count_vectors)\n",
    "df['topic'] = document_topic_matrix.argmax(axis=1)\n",
    "pd.crosstab(df['topic'], df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d4782e-2f96-444c-b803-6931d53a8424",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(tm, count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9281255e-dd49-4bfa-a222-e7973b266a51",
   "metadata": {},
   "source": [
    "The topics do not neatly align with the classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9733f3c2-def8-458b-83c5-68c01d646fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_display = pyLDAvis.sklearn.prepare(tm, count_vectors, count_vectorizer, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9950581c-aa4d-4522-bb14-8c69fcc827f9",
   "metadata": {},
   "source": [
    "Instead of aligning with the drug's route of administration, which is what the classifier was trained to predict, the topics seem to align more with the drug's purpose. We can see this by setting lambda to 0 and inspecting the Top-30 Most Relevant Terms for each topic. For example, Topic 1 seems to be about immunotherapy and cancer fighting drugs. Topic 2 seems to be about psychiatric drugs like antidepressants and antipsychotics. Topic 3 seems to be about hormonal drugs for hypothyroidism or adrenal issues. Topic 4 seems to be about dental products, which is corroborated by the topic-target cross-tabulation above. Topic 5 seems to be a mix of sunscreen and painkillers, which is interesting. This topic is the most aligned with the classifier because it is dominated by the TOPICAL class. This is also reflected in the fact that one of its most common and most relevant words is \"sun,\" which is also one of the classifier's most informative features for the TOPICAL class. Finally, Topic 6 seems to be about antibiotics and antidiabetic drugs. It is interesting that the the topics most aligned with a specific class (Topics 4 and 5 with DENTAL and TOPICAL, respectively) are those with the greatest intertopic distances. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48078efb-6c05-4362-bca1-80b20ec53de6",
   "metadata": {},
   "source": [
    "# Recommendations and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a6dab-519d-40c8-84a0-42f7c158311f",
   "metadata": {},
   "source": [
    "## 1. More Aggressive Stopword Removal\n",
    "\n",
    "Some tokens like \"dose,\" \"patients,\" and \"mg\" are very common. This is handled by the TF-IDF vectors fed into the classifier. However, the topic model uses bag-of-words vectors, so these very common tokens dominate many of the topics. Removing them may help produce better defined topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97be6208-b117-4f13-8de1-042ea3c2e0bc",
   "metadata": {},
   "source": [
    "## 2. Lemmatization\n",
    "\n",
    "This project did not include lemmatization as a preprocessing step. As a result, there are many tokens that convey very similar information like \"dose,\" \"dosage,\" and \"dosing.\" Collapsing these into a single lemma could remove feature redundancy and noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df12e37-13d4-4717-a73b-3133267975f2",
   "metadata": {},
   "source": [
    "## 3. Class Balancing\n",
    "\n",
    "There is pretty dramatic class imbalance among the classifier target: route of administration. This project did not balance the classes before training the classifier or topic model. Future work should see how balancing the training data affects the classifier's performance and the extracted topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499fbec6-81f9-47d6-b258-7cc92dbff784",
   "metadata": {},
   "source": [
    "# Link to GitHub Repo\n",
    "\n",
    "https://github.com/andrewabeles/drug-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0b4bb-b508-4eeb-9eb4-510f554d8508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
